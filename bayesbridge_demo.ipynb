{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesbridge import BayesBridge\n",
    "from simulate_data import simulate_design, simulate_outcome\n",
    "from util import mcmc_summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayesBridge supports both dense (numpy array) and sparse (scipy sparse matrix) design matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obs, n_pred = 10 ** 4, 10 ** 3\n",
    "\n",
    "X = simulate_design(\n",
    "    n_obs, n_pred, \n",
    "    corr_dense_design=False,\n",
    "    binary_frac=.6,\n",
    "    binary_pred_freq=.2,\n",
    "    categorical_frac=.3,\n",
    "    n_category=5,\n",
    "    shuffle_columns=True,\n",
    "    format_='sparse',\n",
    "    seed=111\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_true = np.zeros(n_pred)\n",
    "beta_true[:5] = 1.5\n",
    "beta_true[5:10] = 1.\n",
    "beta_true[10:15] = .5\n",
    "\n",
    "n_trial = np.ones(X.shape[0]) # Binary outcome.\n",
    "y = simulate_outcome(\n",
    "    X, beta_true, intercept=0., \n",
    "    n_trial=n_trial, model='logit', seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally include the first 'n_coef_without_shrinkage' columns of the design matrix as fixed effects with Gaussian priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge = BayesBridge(\n",
    "    y, X, model='logit',\n",
    "    add_intercept=True, \n",
    "    center_predictor=True,\n",
    "        # Do not manually add intercept to or center X.\n",
    "    n_coef_without_shrinkage=0, \n",
    "        # Number of coefficients without shrinkage i.e. fixed effects\n",
    "    prior_sd_for_intercept=float('inf'),\n",
    "    prior_sd_for_unshrunk=float('inf'),\n",
    "        # Set it to float('inf') for a flat prior.\n",
    "    regularizing_slab_size=2.,\n",
    "        # Weakly constrain the magnitude of coefficients under shrinkage.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Gibbs sampler. The BayesBridge uses a prior $ \\pi(\\beta_j \\, | \\, \\tau) \\propto \\tau^{-1} \\exp\\left( - \\, \\left| \\tau^{-1} \\beta_j \\right|^\\alpha \\right) $ for $0 < \\alpha \\leq 1$. The default is $\\alpha = 1 / 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_output = bridge.gibbs(\n",
    "    n_burnin=0, n_post_burnin=250, thin=1, \n",
    "    init={'global_shrinkage': .01},\n",
    "    sampling_method='cg',\n",
    "    bridge_exponent=.5,\n",
    "    seed=111\n",
    ")\n",
    "samples = mcmc_output['samples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check convergence by looking at the traceplot for posterior log-density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "plt.plot(samples['logp'])\n",
    "plt.xlabel('MCMC iteration')\n",
    "plt.ylabel('Posterior log density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart MCMC from the last iteration with 'gibbs_additional_iter()'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_output = bridge.gibbs_additional_iter(\n",
    "    mcmc_output, n_iter=250\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add more samples (while keeping the previous ones) with 'merge=True'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_output = bridge.gibbs_additional_iter(\n",
    "    mcmc_output, n_iter=750, merge=True\n",
    ")\n",
    "samples = mcmc_output['samples']\n",
    "coef_samples = samples['beta'][1:, :] # Extract all but the intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check mixing of regression coefficients and their posterior marginals.\n",
    "\n",
    "Mixing of the global shrinkage parameter and hence of the log-density leave something to be desired for large-scale problems, but typically the convergence is quick and mixing of the regression coefficients is adequate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "plt.plot(coef_samples[[0, 5, 10, 15], :].T)\n",
    "plt.xlabel('MCMC iteration')\n",
    "plt.ylabel(r'$\\beta_j$', rotation=0, labelpad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.rcParams['font.size'] = 20\n",
    "\n",
    "n_coef_to_plot = 25\n",
    "\n",
    "mcmc_summarizer.plot_conf_interval(\n",
    "    coef_samples, conf_level=.95, \n",
    "    n_coef_to_plot=n_coef_to_plot, marker_scale=1.4\n",
    ");\n",
    "plt.plot(\n",
    "    beta_true[:n_coef_to_plot], '--', color='tab:orange',\n",
    "    label='True value'\n",
    ")\n",
    "plt.xlabel(r'Coefficient index $j$')\n",
    "plt.ylabel(r'$\\beta_j$', rotation=0, labelpad=10)\n",
    "plt.xticks([0, 5, 10, 15, 20])\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
